{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad325c18-f029-4528-8614-463530d1d5a0",
   "metadata": {},
   "source": [
    "### Installing Transformers as would be used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "221e8ae7-3983-41e5-9bde-97273d83663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aniekan\\anaconda3\\envs\\sentiment\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d32a87-af38-43db-9fb7-877404a1f79e",
   "metadata": {},
   "source": [
    "### The compressed data is read. [Here](https://www.kaggle.com/datasets/bittlingmayer/amazonreviews/data) is the Amazon dataset used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13854076-6bd5-40aa-b09a-32c3d5950cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import bz2\n",
    "\n",
    "def decompress_bz2(file_path, output_path):\n",
    "    with bz2.open(file_path, 'rt', encoding='utf-8') as file:\n",
    "        with open(output_path, 'w', encoding='utf-8') as out_file:\n",
    "            out_file.write(file.read())\n",
    "\n",
    "# Decompress the files\n",
    "decompress_bz2('train.ft.txt.bz2', 'train.ft.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4468102-76a0-4c68-9a7a-9893d5fa0dd2",
   "metadata": {},
   "source": [
    "### The data is now analysed to see its shape, properties and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0c6806-aca6-455c-98bc-302baf4b909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            label, text = line.split(' ', 1)\n",
    "            label = int(label.replace('__label__', ''))\n",
    "            data.append((label, text.strip()))\n",
    "    return pd.DataFrame(data, columns=['label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "001b2ae2-3b59-4066-bd58-e3ef8ec4f7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599995</th>\n",
       "      <td>1</td>\n",
       "      <td>Don't do it!!: The high chair looks great when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599996</th>\n",
       "      <td>1</td>\n",
       "      <td>Looks nice, low functionality: I have used thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599997</th>\n",
       "      <td>1</td>\n",
       "      <td>compact, but hard to clean: We have a small ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599998</th>\n",
       "      <td>1</td>\n",
       "      <td>what is it saying?: not sure what this book is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599999</th>\n",
       "      <td>2</td>\n",
       "      <td>Makes My Blood Run Red-White-And-Blue: I agree...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "0            2  Stuning even for the non-gamer: This sound tra...\n",
       "1            2  The best soundtrack ever to anything.: I'm rea...\n",
       "2            2  Amazing!: This soundtrack is my favorite music...\n",
       "3            2  Excellent Soundtrack: I truly like this soundt...\n",
       "4            2  Remember, Pull Your Jaw Off The Floor After He...\n",
       "...        ...                                                ...\n",
       "3599995      1  Don't do it!!: The high chair looks great when...\n",
       "3599996      1  Looks nice, low functionality: I have used thi...\n",
       "3599997      1  compact, but hard to clean: We have a small ho...\n",
       "3599998      1  what is it saying?: not sure what this book is...\n",
       "3599999      2  Makes My Blood Run Red-White-And-Blue: I agree...\n",
       "\n",
       "[3600000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = parse_data('train.ft.txt')\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62a31f6d-f713-4541-9221-76e849ae043c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only two unique classes are used as targets\n",
    "train['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac1f92ef-7b03-4f49-9283-540990735d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599995</th>\n",
       "      <td>1</td>\n",
       "      <td>Don't do it!!: The high chair looks great when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599996</th>\n",
       "      <td>1</td>\n",
       "      <td>Looks nice, low functionality: I have used thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599997</th>\n",
       "      <td>1</td>\n",
       "      <td>compact, but hard to clean: We have a small ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599998</th>\n",
       "      <td>1</td>\n",
       "      <td>what is it saying?: not sure what this book is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599999</th>\n",
       "      <td>0</td>\n",
       "      <td>Makes My Blood Run Red-White-And-Blue: I agree...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "0            0  Stuning even for the non-gamer: This sound tra...\n",
       "1            0  The best soundtrack ever to anything.: I'm rea...\n",
       "2            0  Amazing!: This soundtrack is my favorite music...\n",
       "3            0  Excellent Soundtrack: I truly like this soundt...\n",
       "4            0  Remember, Pull Your Jaw Off The Floor After He...\n",
       "...        ...                                                ...\n",
       "3599995      1  Don't do it!!: The high chair looks great when...\n",
       "3599996      1  Looks nice, low functionality: I have used thi...\n",
       "3599997      1  compact, but hard to clean: We have a small ho...\n",
       "3599998      1  what is it saying?: not sure what this book is...\n",
       "3599999      0  Makes My Blood Run Red-White-And-Blue: I agree...\n",
       "\n",
       "[3600000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#They are mapped from [2,1] to [1,0]\n",
    "df = train.copy()\n",
    "df.label = df.label.map({2:0, 1:1})  # 1 are negatives (targeted class)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f31f56f-7e19-4662-8d3f-3e6e90ea8079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>A revelation of life in small town America in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>Great biography of a very interesting journali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>Interesting Subject; Poor Presentation: You'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>Don't buy: The box looked used and it is obvio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>Beautiful Pen and Fast Delivery.: The pen was ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         0  Stuning even for the non-gamer: This sound tra...\n",
       "1         0  The best soundtrack ever to anything.: I'm rea...\n",
       "2         0  Amazing!: This soundtrack is my favorite music...\n",
       "3         0  Excellent Soundtrack: I truly like this soundt...\n",
       "4         0  Remember, Pull Your Jaw Off The Floor After He...\n",
       "...     ...                                                ...\n",
       "9995      0  A revelation of life in small town America in ...\n",
       "9996      0  Great biography of a very interesting journali...\n",
       "9997      1  Interesting Subject; Poor Presentation: You'd ...\n",
       "9998      1  Don't buy: The box looked used and it is obvio...\n",
       "9999      0  Beautiful Pen and Fast Delivery.: The pen was ...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We're going to use only 10000 records from the data for faster training\n",
    "df = df[0:10000]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5aebefd-a736-4f50-bdf4-3f3be0b9bc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   10000 non-null  int64 \n",
      " 1   text    10000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "485a8d9a-a195-4a8c-a16b-21e51f71ca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    5097\n",
      "0    4903\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data is balanced\n",
    "print(df['label'].value_counts())\n",
    "df['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59914d7f-7ac3-4461-8eb8-2c1fd0f40295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformersNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Using cached tokenizers-0.20.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Using cached transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "Using cached safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "Using cached tokenizers-0.20.1-cp311-none-win_amd64.whl (2.4 MB)\n",
      "Installing collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.4.5 tokenizers-0.20.1 transformers-4.45.2\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f87fe2-938b-4669-9a7e-33c298ee49db",
   "metadata": {},
   "source": [
    "## Importing the necessary training modules and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be5df746-32f2-494c-bfea-d4c91ca8970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4306debb-d357-4507-93fe-38ec28aae51e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a2736c-3217-42ca-b1be-03128edbc664",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df[\"text\"])\n",
    "y = list(df[\"label\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y)\n",
    "\n",
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
    "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf9700f-0f66-485f-bce8-be2a1c0ea626",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c5a01c7-84d6-4a82-a681-857b1db0e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X and y into Pytorch Dataset (as transformers accept data in that format)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "# This method is used to retrieve a single sample from the dataset.\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c23b58b-8cde-4fd4-824c-f0c4c6889453",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "test_dataset = Dataset(X_test_tokenized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adfa9bd7-e58e-4f2d-9fd0-f9a0d7a881a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1037,  3969,  2732,  2002,  2003,  1024,  2023,  2201,  2003,\n",
       "          2061,  2214,  2082,  1999,  2049,  3082,  7294, 10299,  1012,  1045,\n",
       "          1005,  1049, 23042,  1012,  2045,  2003,  2498,  6517,  2006,  2023,\n",
       "          2201,  1006,  3272,  2005,  1996,  2200,  3809,  2299,  3336, 18938,\n",
       "          5886,  1063,  2055,  3352,  2019, 16655,  2595,  5051, 25572,  3372,\n",
       "          2269,  1065,  1007,  1012,  2009,  1005,  1055,  1037,  2514,  2204,\n",
       "          3729,  1012,  2130,  1996,  2681, 14074, 11488,  3351,  2650,  2003,\n",
       "          4569,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ceb0195-ce3f-47f2-a1e0-1a37bf24c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95c4c9c5-3c16-4397-a2fb-05ccf1a347b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.66.5)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.4.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\aniekan\\anaconda3\\lib\\site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "   ---------------------------------------- 0.0/330.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/330.9 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 30.7/330.9 kB 660.6 kB/s eta 0:00:01\n",
      "   --- ----------------------------------- 30.7/330.9 kB 660.6 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 61.4/330.9 kB 328.2 kB/s eta 0:00:01\n",
      "   ---------- ---------------------------- 92.2/330.9 kB 403.5 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 122.9/330.9 kB 481.4 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 122.9/330.9 kB 481.4 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 174.1/330.9 kB 477.7 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 256.0/330.9 kB 630.2 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 286.7/330.9 kB 655.2 kB/s eta 0:00:01\n",
      "   -------------------------------------  327.7/330.9 kB 655.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 330.9/330.9 kB 641.4 kB/s eta 0:00:00\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07d0757b-c386-47b0-ba93-0fa79563eb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47abcbb0-0ff6-498d-ac7c-2b9aa368d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8\n",
    "\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cd30a16-c73d-4db5-9913-0e390f235047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 10:46:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.319400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.235000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.27717655181884765, metrics={'train_runtime': 38829.6421, 'train_samples_per_second': 0.206, 'train_steps_per_second': 0.026, 'total_flos': 1537555229760000.0, 'train_loss': 0.27717655181884765, 'epoch': 1.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4edcbf6e-a528-4878-8220-8b792dd79a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 19:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.21620133519172668,\n",
       " 'eval_accuracy': 0.9335,\n",
       " 'eval_precision': 0.9267822736030829,\n",
       " 'eval_recall': 0.9440628066732091,\n",
       " 'eval_f1': 0.9353427321341761,\n",
       " 'eval_runtime': 1145.1118,\n",
       " 'eval_samples_per_second': 1.747,\n",
       " 'eval_steps_per_second': 0.218,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2035a463-6b4f-4cbc-be76-9e9227cc3395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.996407   0.00359302]]\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "def classify_text(text, model, tokenizer):\n",
    "    # Check if CUDA is available, otherwise fallback to CPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Tokenize the input text and move it to the selected device (CPU or GPU)\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    \n",
    "    # Move the model to the selected device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Get model outputs\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    # Apply softmax to the logits to get probabilities\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Move the predictions back to CPU and convert to numpy array (if needed)\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "    \n",
    "    # Print the predictions\n",
    "    print(predictions)\n",
    "    \n",
    "    # Check the first index and print the corresponding label\n",
    "    if predictions[0][0] > 0.5:\n",
    "        print(\"Positive\")\n",
    "    else:\n",
    "        print(\"Negative\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example call to classify text\n",
    "predictions = classify_text(\"The mobile is awesome\", model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f176055e-fb66-4484-a010-2edb986ad6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0022754 0.9977246]]\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "predictions = classify_text(\"The mobile is bad\", model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4da207cd-5d6d-4156-a653-17c07352b250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00408918 0.9959109 ]]\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "predictions = classify_text(\"\"\"After purchasing such an expensive item we do not expect such damaged item box. \n",
    "The box was damaged in various places and had tape applied on the front. I don't know whether the damage was\n",
    "due to the box falling or not. I am also confused whether the box and PS5 might have suffered any damage due to the fall. \n",
    "I am not satisfied. You have to give proper box packing without any damage.\"\"\", model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd9a0f-41a6-4b2d-a146-e59a9d127891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
